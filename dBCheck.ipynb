{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the CSV file\n",
        "# Replace 'survey_data.csv' with the path to your CSV file\n",
        "data = pd.read_csv('Earcare.csv')\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "print(\"Dataset preview:\")\n",
        "print(data.head())\n",
        "\n",
        "# Step 1: Handle missing values\n",
        "# Fill missing numerical values with the mean of the column\n",
        "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "data[numerical_columns] = data[numerical_columns].fillna(data[numerical_columns].mean())\n",
        "\n",
        "# Fill missing categorical values with the mode of the column\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "data[categorical_columns] = data[categorical_columns].fillna(data[categorical_columns].mode().iloc[0])\n",
        "\n",
        "# Step 2: Encode categorical variables\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data[column] = le.fit_transform(data[column])\n",
        "    label_encoders[column] = le  # Save encoder for inverse transformation if needed\n",
        "\n",
        "# Step 3: Separate features and target variable\n",
        "# Replace 'target_column_name' with the name of your target column (e.g., 'Ear Health')\n",
        "X = data.drop('RISK', axis=1)\n",
        "y = data['RISK']\n",
        "\n",
        "# Step 4: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display shapes of resulting datasets\n",
        "print(f\"Training features shape: {X_train.shape}\")\n",
        "print(f\"Testing features shape: {X_test.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Testing labels shape: {y_test.shape}\")\n",
        "print(X_train)\n"
      ],
      "metadata": {
        "id": "KKKsNMY5GLHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "data = pd.read_csv('Earcare.csv')\n",
        "\n",
        "# Handle missing values\n",
        "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "data[numerical_columns] = data[numerical_columns].fillna(data[numerical_columns].mean())\n",
        "\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "for column in categorical_columns:\n",
        "    data[column] = data[column].fillna(data[column].mode().iloc[0])\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data[column] = le.fit_transform(data[column])\n",
        "    label_encoders[column] = le\n",
        "X = data.drop('RISK', axis=1)\n",
        "y = data['RISK']\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=4)\n",
        "X_synthetic, y_synthetic = smote.fit_resample(X, y)\n",
        "\n",
        "synthetic_data = pd.DataFrame(X_synthetic, columns=X.columns)\n",
        "synthetic_data['RISK'] = y_synthetic\n",
        "synthetic_data = synthetic_data.sample(n=1000, replace=True, random_state=42)\n",
        "synthetic_data = synthetic_data.reset_index(drop=True)\n",
        "synthetic_data.to_csv('synthetic_earcare_data.csv', index=False)\n",
        "print(f\"Generated {len(synthetic_data)} rows of synthetic data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaW5BicVzkg0",
        "outputId": "0c18ae1a-c4a2-4ed3-e2d2-441b87a8637a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 1000 rows of synthetic data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv('Earcare.csv')\n",
        "\n",
        "# Handle missing values\n",
        "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "data[numerical_columns] = data[numerical_columns].fillna(data[numerical_columns].mean())\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('RISK', axis=1)\n",
        "y = data['RISK']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Display the results\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({'feature': X.columns, 'importance': rf_classifier.feature_importances_})\n",
        "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmiW8ozhth7N",
        "outputId": "f5a63e1a-6042-4a77-a9b8-c90b0bec7481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        94\n",
            "           1       1.00      1.00      1.00       106\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "                                              feature  importance\n",
            "7   How often do you take breaks while using headp...    0.205922\n",
            "10  While Using Headphones/earphones are you able ...    0.166321\n",
            "4   What activities do you usually use headphones ...    0.111099\n",
            "14  Do you take any precautions to protect your he...    0.083601\n",
            "5      At what volume level do you typically listen?     0.073467\n",
            "6   Do you increase the volume when in noisy envir...    0.071524\n",
            "8   Do you use any volume-limiting features on you...    0.057354\n",
            "1                                              Gender    0.046197\n",
            "3   On average, how many hours per day do you use ...    0.043744\n",
            "12  Are you aware of the potential risks of prolon...    0.037549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load and preprocess the data (using the same steps as before)\n",
        "data = pd.read_csv('Earcare.csv')\n",
        "\n",
        "# Handle missing values\n",
        "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "data[numerical_columns] = data[numerical_columns].fillna(data[numerical_columns].mean())\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('RISK', axis=1)\n",
        "y = data['RISK']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the XGBoost Classifier\n",
        "xgb_classifier = XGBClassifier(random_state=42)\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Display the results\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({'feature': X.columns, 'importance': xgb_classifier.feature_importances_})\n",
        "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff-Mx0Bnt08g",
        "outputId": "8c82e62f-0e20-4386-fc96-9d6736c31151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        94\n",
            "           1       1.00      1.00      1.00       106\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "                                              feature  importance\n",
            "10  While Using Headphones/earphones are you able ...    0.428018\n",
            "7   How often do you take breaks while using headp...    0.242474\n",
            "14  Do you take any precautions to protect your he...    0.167438\n",
            "4   What activities do you usually use headphones ...    0.130577\n",
            "13  Do you experience any of the following after u...    0.012794\n",
            "6   Do you increase the volume when in noisy envir...    0.011168\n",
            "1                                              Gender    0.005059\n",
            "5      At what volume level do you typically listen?     0.002380\n",
            "9   Do you have difficulty hearing in noisy enviro...    0.000053\n",
            "3   On average, how many hours per day do you use ...    0.000040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load and preprocess the data\n",
        "data = pd.read_csv('Earcare.csv')\n",
        "\n",
        "# Handle missing values\n",
        "data = data.fillna(data.mode().iloc[0])\n",
        "\n",
        "# Encode categorical variables\n",
        "le = LabelEncoder()\n",
        "for column in data.select_dtypes(include=['object']):\n",
        "    data[column] = le.fit_transform(data[column])\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('RISK', axis=1)\n",
        "y = data['RISK']\n",
        "\n",
        "# Create a pipeline with preprocessing and SVM classifier\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(kernel='rbf', random_state=42))\n",
        "])\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Output the cross-validation results\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean accuracy: {cv_scores.mean():.2f} (+/- {cv_scores.std() * 2:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ANZyArZyHHS",
        "outputId": "c367c201-5e0f-40aa-fc33-4d0547e99d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
            "Mean accuracy: 1.00 (+/- 0.00)\n"
          ]
        }
      ]
    }
  ]
}